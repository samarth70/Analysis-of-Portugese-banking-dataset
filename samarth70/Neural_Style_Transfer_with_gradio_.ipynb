{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Style Transfer with gradio .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7bP4tiM8dtl1kAsi8hKAC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samarth70/Analysis-of-Portugese-banking-dataset/blob/master/samarth70/Neural_Style_Transfer_with_gradio_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e-6IH1HRNnD"
      },
      "source": [
        "%%capture\n",
        "!pip install gradio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haTY0gGEPdOu"
      },
      "source": [
        "import gradio as gr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC7xVOx7zE9D"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as display\n",
        "import matplotlib as mpl\n",
        "import os\n",
        "import time\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import time\n",
        "import functools\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kg4mzkNruD8L",
        "outputId": "0a90fb98-7cd7-475a-c469-b0cce8899ed2"
      },
      "source": [
        "!mkdir nstmodel \n",
        "!wget -c https://storage.googleapis.com/tfhub-modules/google/magenta/arbitrary-image-stylization-v1-256/2.tar.gz -O - | tar -xz -C /content/nstmodel\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-10 13:17:44--  https://storage.googleapis.com/tfhub-modules/google/magenta/arbitrary-image-stylization-v1-256/2.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.142.128, 74.125.195.128, 2607:f8b0:400e:c08::80, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.142.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 85627349 (82M) [application/x-tar]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>]  81.66M  76.6MB/s    in 1.1s    \n",
            "\n",
            "2021-02-10 13:17:45 (76.6 MB/s) - written to stdout [85627349/85627349]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsxV3105pGyz"
      },
      "source": [
        "import tensorflow.keras\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "\n",
        "# Disable scientific notation for clarity\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "# Load the model\n",
        "model = tensorflow.keras.models.load_model('/content/nstmodel')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or4H3jtCc3Yq"
      },
      "source": [
        "def tensor_to_image(tensor):\n",
        "  tensor = tensor*255\n",
        "  tensor = np.array(tensor, dtype=np.uint8)\n",
        "  if np.ndim(tensor)>3:\n",
        "    assert tensor.shape[0] == 1\n",
        "    tensor = tensor[0]\n",
        "  return PIL.Image.fromarray(tensor)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HgBL3bCJwEZ"
      },
      "source": [
        "def save_image(image, filename):\n",
        "  \"\"\"\n",
        "    Saves unscaled Tensor Images.\n",
        "    Args:\n",
        "      image: 3D image tensor. [height, width, channels]\n",
        "      filename: Name of the file to save to.\n",
        "  \"\"\"\n",
        "  if not isinstance(image, Image.Image):\n",
        "    image = tf.clip_by_value(image, 0, 255)\n",
        "    image = Image.fromarray(tf.cast(image, tf.uint8).numpy())\n",
        "  image.save(\"%s.jpg\" % filename)\n",
        "  print(\"Saved as %s.jpg\" % filename)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHIud3iSa11t"
      },
      "source": [
        "import cv2\n",
        "\n",
        "def gray_scaled(img):\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  img2 = np.zeros_like(img)\n",
        "  img2[:,:,0] = gray\n",
        "  img2[:,:,1] = gray\n",
        "  img2[:,:,2] = gray\n",
        "  return img2\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBcz5IelMLRc"
      },
      "source": [
        "def transform_mymodel(content_image,style_image):\n",
        "  # content_image = plt.imread(content_image_path)\n",
        "  # style_image = plt.imread(style_image_path)\n",
        "  # Convert to float32 numpy array, add batch dimension, and normalize to range [0, 1]\n",
        "  # content_image=gray_scaled(content_image)\n",
        "  content_image = content_image.astype(np.float32)[np.newaxis, ...] / 255.0\n",
        "  style_image = style_image.astype(np.float32)[np.newaxis, ...] / 255.0\n",
        "  # Optionally resize the images. It is recommended that the style image is about\n",
        "  # 256 pixels (this size was used when training the style transfer network).\n",
        "  # The content image can be any size.\n",
        "  style_image = tf.image.resize(style_image, (256, 256))\n",
        "\n",
        "  # Stylize image.\n",
        "  outputs = model(tf.constant(content_image), tf.constant(style_image))\n",
        "  stylized_image = outputs[0]\n",
        "  # stylized = tf.image.resize(stylized_image, (356, 356))\n",
        "  stylized_image =tensor_to_image(stylized_image)\n",
        "  save_image(stylized_image,'stylized')\n",
        "  return stylized_image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7OaaI836mme"
      },
      "source": [
        "def gradio_intrface(mymodel):\n",
        "# initializing the input component \n",
        "  image1 = gr.inputs.Image() \n",
        "  image2 = gr.inputs.Image() \n",
        "  stylizedimg=gr.outputs.Image()\n",
        "  gr.Interface(fn=mymodel, inputs= [image1,image2] , outputs= stylizedimg,title='Style Transfer').launch(share=False,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZalVEN2YWvHv"
      },
      "source": [
        "gradio_intrface(transform_mymodel)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}